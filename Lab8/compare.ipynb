{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7eaf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from itertools import product\n",
    "import warnings\n",
    "from sklearn.decomposition import PCA\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad890d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmeans import (\n",
    "    KMeans, \n",
    "    extract_numerical_features, \n",
    "    preprocess_data, \n",
    "    calculate_silhouette_scores as kmeans_silhouette,\n",
    "    calculate_inertia_values,\n",
    "    find_optimal_k_elbow\n",
    ")\n",
    "from dbscan import (\n",
    "    DBSCAN,\n",
    "    extract_numerical_features as dbscan_filter_features,\n",
    "    preprocess_data as dbscan_preprocess,\n",
    "    calculate_silhouette_score as dbscan_silhouette,\n",
    "    optimize_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8efe532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "KMEANS_COLOR = '#1f77b4'  # Blue\n",
    "DBSCAN_COLOR = '#ff7f0e'  # Orange\n",
    "DATASET_COLORS = ['#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', \"#3ec44a\", '#bcbd22']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a5f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_by_id(dataset_id):\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading dataset ID: {dataset_id}\")\n",
    "        dataset = fetch_ucirepo(id=dataset_id)\n",
    "        \n",
    "        # Filter numerical features\n",
    "        filtered_dataset, removed_features = extract_numerical_features(dataset)\n",
    "        \n",
    "        if filtered_dataset.data.features.shape[1] == 0:\n",
    "            print(f\" Dataset {dataset_id} has no numerical features, skipping...\")\n",
    "            return None, None, None, None\n",
    "            \n",
    "        # Extract data\n",
    "        X = filtered_dataset.data.features.values\n",
    "        y = filtered_dataset.data.targets.values.ravel()\n",
    "        feature_names = list(filtered_dataset.data.features.columns)\n",
    "        \n",
    "        # Get dataset name from metadata\n",
    "        dataset_name = getattr(dataset.metadata, 'name', f'Dataset_{dataset_id}')\n",
    "        \n",
    "        print(f\" Loaded {dataset_name}: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "        if removed_features:\n",
    "            print(f\"   Removed {len(removed_features)} categorical features\")\n",
    "            \n",
    "        return X, y, feature_names, dataset_name\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error loading dataset {dataset_id}: {str(e)}\")\n",
    "        return None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f66e0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans_analysis(X, dataset_name, max_k=10):\n",
    "    \n",
    "    print(f\"Running K-means analysis for {dataset_name}...\")\n",
    "    \n",
    "    # Find optimal k using elbow method\n",
    "    inertias = calculate_inertia_values(X, max_k)\n",
    "    \n",
    "    # Detect optimal k\n",
    "    optimal_k = find_optimal_k_elbow(inertias)\n",
    "    \n",
    "    # Run K-means with optimal k\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    if optimal_k > 1:\n",
    "        silhouette_score, _ = kmeans_silhouette(X, labels)\n",
    "    else:\n",
    "        silhouette_score = 0.0\n",
    "    \n",
    "    # Calculate cluster sizes\n",
    "    cluster_sizes = []\n",
    "    for i in range(optimal_k):\n",
    "        size = np.sum(labels == i)\n",
    "        cluster_sizes.append(size)\n",
    "    \n",
    "    results = {\n",
    "        'algorithm': 'K-Means',\n",
    "        'dataset': dataset_name,\n",
    "        'optimal_k': optimal_k,\n",
    "        'labels': labels,\n",
    "        'centroids': kmeans.cluster_centers,\n",
    "        'inertia': kmeans.inertia_,\n",
    "        'silhouette_score': silhouette_score,\n",
    "        'cluster_sizes': cluster_sizes,\n",
    "        'inertias': inertias,\n",
    "        'n_clusters': optimal_k,\n",
    "        'n_noise': 0,  # K-means doesn't have noise points\n",
    "        'noise_ratio': 0.0\n",
    "    }\n",
    "    \n",
    "    print(f\"   K-means: k={optimal_k}, silhouette={silhouette_score:.3f}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b429948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dbscan_analysis(X, dataset_name):\n",
    "\n",
    "    print(f\"Running DBSCAN analysis for {dataset_name}...\")\n",
    "    \n",
    "    # Adjust max_combinations based on dataset size for efficiency\n",
    "    n_samples = X.shape[0]\n",
    "    if n_samples > 2000:\n",
    "        max_combinations = 10  # Reduce combinations for large datasets\n",
    "    elif n_samples > 1000:\n",
    "        max_combinations = 15\n",
    "    else:\n",
    "        max_combinations = 20\n",
    "    \n",
    "    print(f\"   Using {max_combinations} parameter combinations for {n_samples} samples\")\n",
    "    \n",
    "    # Find optimal parameters\n",
    "    param_results = optimize_parameters(X, max_combinations=max_combinations)\n",
    "    best_params = param_results[0]\n",
    "    \n",
    "    # Run DBSCAN with optimal parameters\n",
    "    dbscan = DBSCAN(epsilon=best_params['epsilon'], min_samples=best_params['min_samples'])\n",
    "    labels = dbscan.fit_predict(X)\n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    silhouette_score = dbscan_silhouette(X, labels)\n",
    "    \n",
    "    # Calculate cluster sizes (excluding noise)\n",
    "    cluster_sizes = []\n",
    "    unique_labels = np.unique(labels)\n",
    "    for label in unique_labels:\n",
    "        if label != -1:  # Exclude noise\n",
    "            size = np.sum(labels == label)\n",
    "            cluster_sizes.append(size)\n",
    "    \n",
    "    results = {\n",
    "        'algorithm': 'DBSCAN',\n",
    "        'dataset': dataset_name,\n",
    "        'optimal_eps': best_params['epsilon'],\n",
    "        'optimal_min_samples': best_params['min_samples'],\n",
    "        'labels': labels,\n",
    "        'silhouette_score': silhouette_score,\n",
    "        'cluster_sizes': cluster_sizes,\n",
    "        'n_clusters': dbscan.num_clusters,\n",
    "        'n_noise': dbscan.noise_count,\n",
    "        'noise_ratio': best_params['noise_ratio'],\n",
    "        'param_results': param_results\n",
    "    }\n",
    "    \n",
    "    print(f\"   DBSCAN: clusters={dbscan.num_clusters}, noise_ratio={best_params['noise_ratio']:.3f}, silhouette={silhouette_score:.3f}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e6f75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_folder():\n",
    "    \n",
    "    folder_path = \"comparison\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Created output folder: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"Using existing output folder: {folder_path}\")\n",
    "    return folder_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d111bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elbow_method_comparison(all_results, output_folder):\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    for i, (dataset_name, results) in enumerate(all_results.items()):\n",
    "        if 'inertias' in results['kmeans']:\n",
    "            inertias = results['kmeans']['inertias']\n",
    "            k_values = range(1, len(inertias) + 1)\n",
    "            color = DATASET_COLORS[i % len(DATASET_COLORS)]\n",
    "            \n",
    "            plt.plot(k_values, inertias, 'o-', linewidth=2, markersize=6, \n",
    "                    label=f'{dataset_name}', color=color, alpha=0.8)\n",
    "            \n",
    "            # Mark optimal k\n",
    "            optimal_k = results['kmeans']['optimal_k']\n",
    "            plt.plot(optimal_k, inertias[optimal_k-1], 's', markersize=10, \n",
    "                    color=color, markeredgecolor='red', markeredgewidth=2)\n",
    "            \n",
    "            # Add text annotation for optimal k\n",
    "            plt.annotate(f'k={optimal_k}', \n",
    "                        xy=(optimal_k, inertias[optimal_k-1]),\n",
    "                        xytext=(5, 5), textcoords='offset points',\n",
    "                        fontsize=10, fontweight='bold', color=color,\n",
    "                        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.xlabel('Number of Clusters (k)', fontsize=12)\n",
    "    plt.ylabel('Inertia (Within-cluster sum of squares)', fontsize=12)\n",
    "    plt.title('Elbow Method Analysis - All Datasets (K-Means)', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = os.path.join(output_folder, '1_elbow_method_all_datasets.png')\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Elbow method comparison saved to: {filename}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7972ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhouette_comparison_per_dataset(all_results, output_folder):\n",
    "    \n",
    "    for dataset_name, results in all_results.items():\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        kmeans_results = results['kmeans']\n",
    "        dbscan_results = results['dbscan']\n",
    "        \n",
    "        # K-means silhouette by k\n",
    "        if 'inertias' in kmeans_results:\n",
    "            max_k = len(kmeans_results['inertias'])\n",
    "            k_values = range(2, max_k + 1)  # Start from k=2 for silhouette\n",
    "            silhouette_scores = []\n",
    "            \n",
    "            # Calculate silhouette scores for different k values\n",
    "            X = results['X_scaled']\n",
    "            for k in k_values:\n",
    "                if k <= max_k:\n",
    "                    kmeans_temp = KMeans(n_clusters=k, random_state=42)\n",
    "                    labels_temp = kmeans_temp.fit_predict(X)\n",
    "                    if k > 1:\n",
    "                        sil_score, _ = kmeans_silhouette(X, labels_temp)\n",
    "                        silhouette_scores.append(sil_score)\n",
    "                    else:\n",
    "                        silhouette_scores.append(0.0)\n",
    "            \n",
    "            ax1.plot(k_values, silhouette_scores, 'o-', color=KMEANS_COLOR, \n",
    "                    linewidth=2, markersize=6, label='K-Means')\n",
    "            ax1.axvline(x=kmeans_results['optimal_k'], color=KMEANS_COLOR, \n",
    "                       linestyle='--', alpha=0.7)\n",
    "            ax1.set_xlabel('Number of Clusters (k)')\n",
    "            ax1.set_ylabel('Silhouette Score')\n",
    "            ax1.set_title(f'K-Means Silhouette Analysis\\n{dataset_name}')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            ax1.legend()\n",
    "        \n",
    "        # DBSCAN parameter analysis\n",
    "        if 'param_results' in dbscan_results:\n",
    "            param_results = dbscan_results['param_results']\n",
    "            eps_values = [r['epsilon'] for r in param_results]\n",
    "            silhouette_scores = [r['silhouette_score'] for r in param_results]\n",
    "            \n",
    "            # Create scatter plot of eps vs silhouette score\n",
    "            scatter = ax2.scatter(eps_values, silhouette_scores, c=silhouette_scores, \n",
    "                                cmap='viridis', s=60, alpha=0.7)\n",
    "            \n",
    "            # Mark optimal point\n",
    "            optimal_eps = dbscan_results['optimal_eps']\n",
    "            optimal_sil = dbscan_results['silhouette_score']\n",
    "            ax2.scatter(optimal_eps, optimal_sil, color='red', s=100, \n",
    "                       marker='*', edgecolor='darkred', linewidth=2, \n",
    "                       label=f'Optimal (eps={optimal_eps:.3f})')\n",
    "            \n",
    "            ax2.set_xlabel('Eps Parameter')\n",
    "            ax2.set_ylabel('Silhouette Score')\n",
    "            ax2.set_title(f'DBSCAN Parameter Analysis\\n{dataset_name}')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            ax2.legend()\n",
    "            plt.colorbar(scatter, ax=ax2, label='Silhouette Score')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        filename = os.path.join(output_folder, f'2_silhouette_analysis_{dataset_name.lower().replace(\" \", \"_\")}.png')\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Silhouette analysis for {dataset_name} saved to: {filename}\")\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a81f983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_size_comparison_per_dataset(all_results, output_folder):\n",
    "    \n",
    "    for dataset_name, results in all_results.items():\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        kmeans_results = results['kmeans']\n",
    "        dbscan_results = results['dbscan']\n",
    "        \n",
    "        # K-means cluster sizes\n",
    "        kmeans_sizes = kmeans_results['cluster_sizes']\n",
    "        if kmeans_sizes:\n",
    "            clusters_k = range(len(kmeans_sizes))\n",
    "            bars1 = ax1.bar(clusters_k, kmeans_sizes, color=KMEANS_COLOR, alpha=0.7, \n",
    "                           label='K-Means Clusters')\n",
    "            ax1.set_xlabel('Cluster ID')\n",
    "            ax1.set_ylabel('Number of Points')\n",
    "            ax1.set_title(f'K-Means Cluster Sizes\\n{dataset_name}\\n(k={len(kmeans_sizes)})')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, size in zip(bars1, kmeans_sizes):\n",
    "                height = bar.get_height()\n",
    "                ax1.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                        f'{size}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        # DBSCAN cluster sizes\n",
    "        dbscan_sizes = dbscan_results['cluster_sizes']\n",
    "        noise_count = dbscan_results['n_noise']\n",
    "        \n",
    "        if dbscan_sizes:\n",
    "            clusters_d = range(len(dbscan_sizes))\n",
    "            bars2 = ax2.bar(clusters_d, dbscan_sizes, color=DBSCAN_COLOR, alpha=0.7, \n",
    "                           label='DBSCAN Clusters')\n",
    "            \n",
    "            # Add noise bar if there are noise points\n",
    "            if noise_count > 0:\n",
    "                noise_bar = ax2.bar(len(dbscan_sizes), noise_count, color='red', alpha=0.7, \n",
    "                                   label='Noise Points')\n",
    "                ax2.text(len(dbscan_sizes), noise_count + noise_count*0.01,\n",
    "                        f'{noise_count}', ha='center', va='bottom', fontsize=9)\n",
    "            \n",
    "            ax2.set_xlabel('Cluster ID (+ Noise)')\n",
    "            ax2.set_ylabel('Number of Points')\n",
    "            ax2.set_title(f'DBSCAN Cluster Sizes\\n{dataset_name}\\n({len(dbscan_sizes)} clusters + {noise_count} noise)')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            ax2.legend()\n",
    "            \n",
    "            # Add value labels on cluster bars\n",
    "            for bar, size in zip(bars2, dbscan_sizes):\n",
    "                height = bar.get_height()\n",
    "                ax2.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                        f'{size}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        filename = os.path.join(output_folder, f'3_cluster_sizes_{dataset_name.lower().replace(\" \", \"_\")}.png')\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Cluster size comparison for {dataset_name} saved to: {filename}\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b48f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhouette_score_by_parameters(all_results, output_folder):\n",
    "    \n",
    "    for dataset_name, results in all_results.items():\n",
    "        if 'param_results' in results['dbscan']:\n",
    "            param_results = results['dbscan']['param_results']\n",
    "            \n",
    "            # Extract parameter data\n",
    "            eps_values = [r['epsilon'] for r in param_results]\n",
    "            min_samples_values = [r['min_samples'] for r in param_results]\n",
    "            silhouette_scores = [r['silhouette_score'] for r in param_results]\n",
    "            \n",
    "            # Create the plot\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            scatter = plt.scatter(eps_values, min_samples_values, c=silhouette_scores, \n",
    "                                cmap='viridis', s=100, alpha=0.8, edgecolors='black', linewidth=0.5)\n",
    "            \n",
    "            # Mark optimal point\n",
    "            optimal_eps = results['dbscan']['optimal_eps']\n",
    "            optimal_min_samples = results['dbscan']['optimal_min_samples']\n",
    "            optimal_silhouette = results['dbscan']['silhouette_score']\n",
    "            \n",
    "            plt.scatter(optimal_eps, optimal_min_samples, color='red', s=200, \n",
    "                       marker='*', edgecolor='darkred', linewidth=2, \n",
    "                       label=f'Optimal (eps={optimal_eps:.3f}, min_samples={optimal_min_samples})')\n",
    "            \n",
    "            plt.xlabel('Eps Parameter', fontsize=12)\n",
    "            plt.ylabel('Min Samples Parameter', fontsize=12)\n",
    "            plt.title(f'DBSCAN: Silhouette Score by Parameters\\n{dataset_name}', fontsize=14, fontweight='bold')\n",
    "            plt.colorbar(scatter, label='Silhouette Score')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            filename = os.path.join(output_folder, f'4_silhouette_by_params_{dataset_name.lower().replace(\" \", \"_\")}.png')\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Silhouette score by parameters for {dataset_name} saved to: {filename}\")\n",
    "            plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a24c183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_noise_ratio_by_parameters(all_results, output_folder):\n",
    "    \n",
    "    for dataset_name, results in all_results.items():\n",
    "        if 'param_results' in results['dbscan']:\n",
    "            param_results = results['dbscan']['param_results']\n",
    "            \n",
    "            # Extract parameter data\n",
    "            eps_values = [r['epsilon'] for r in param_results]\n",
    "            min_samples_values = [r['min_samples'] for r in param_results]\n",
    "            noise_ratios = [r['noise_ratio'] for r in param_results]\n",
    "            \n",
    "            # Create the plot\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            scatter = plt.scatter(eps_values, min_samples_values, c=noise_ratios, \n",
    "                                cmap='Reds', s=100, alpha=0.8, edgecolors='black', linewidth=0.5)\n",
    "            \n",
    "            # Mark optimal point\n",
    "            optimal_eps = results['dbscan']['optimal_eps']\n",
    "            optimal_min_samples = results['dbscan']['optimal_min_samples']\n",
    "            optimal_noise_ratio = results['dbscan']['noise_ratio']\n",
    "            \n",
    "            plt.scatter(optimal_eps, optimal_min_samples, color='blue', s=200, \n",
    "                       marker='*', edgecolor='darkblue', linewidth=2, \n",
    "                       label=f'Optimal (eps={optimal_eps:.3f}, min_samples={optimal_min_samples})')\n",
    "            \n",
    "            plt.xlabel('Eps Parameter', fontsize=12)\n",
    "            plt.ylabel('Min Samples Parameter', fontsize=12)\n",
    "            plt.title(f'DBSCAN: Noise Ratio by Parameters\\n{dataset_name}', fontsize=14, fontweight='bold')\n",
    "            plt.colorbar(scatter, label='Noise Ratio')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            filename = os.path.join(output_folder, f'5_noise_ratio_by_params_{dataset_name.lower().replace(\" \", \"_\")}.png')\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Noise ratio by parameters for {dataset_name} saved to: {filename}\")\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c323672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering_visualizations(all_results, output_folder):\n",
    "    \n",
    "    for dataset_name, results in all_results.items():\n",
    "        # Get the data and results\n",
    "        X = results['X_scaled']\n",
    "        kmeans_labels = results['kmeans']['labels']\n",
    "        dbscan_labels = results['dbscan']['labels']\n",
    "        \n",
    "        # Apply PCA if data has more than 2 dimensions\n",
    "        if X.shape[1] > 2:\n",
    "            pca = PCA(n_components=2, random_state=42)\n",
    "            X_2d = pca.fit_transform(X)\n",
    "            explained_variance = pca.explained_variance_ratio_\n",
    "            pca_info = f\"PCA: {explained_variance[0]:.1%} + {explained_variance[1]:.1%} = {sum(explained_variance):.1%} variance\"\n",
    "        else:\n",
    "            X_2d = X\n",
    "            pca_info = \"Original 2D data\"\n",
    "        \n",
    "        # Create the plot\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # K-means visualization\n",
    "        kmeans_unique_labels = np.unique(kmeans_labels)\n",
    "        n_kmeans_clusters = len(kmeans_unique_labels)\n",
    "        \n",
    "        # Use a colormap for K-means\n",
    "        colors_kmeans = plt.cm.Set1(np.linspace(0, 1, n_kmeans_clusters))\n",
    "        \n",
    "        for i, label in enumerate(kmeans_unique_labels):\n",
    "            mask = kmeans_labels == label\n",
    "            ax1.scatter(X_2d[mask, 0], X_2d[mask, 1], \n",
    "                       c=[colors_kmeans[i]], s=50, alpha=0.7, \n",
    "                       label=f'Cluster {label}', edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        # Plot K-means centroids if available and data is 2D or we can project them\n",
    "        if X.shape[1] <= 2 and 'centroids' in results['kmeans']:\n",
    "            centroids = results['kmeans']['centroids']\n",
    "            ax1.scatter(centroids[:, 0], centroids[:, 1], \n",
    "                       c='red', marker='x', s=200, linewidth=3, label='Centroids')\n",
    "        elif X.shape[1] > 2 and 'centroids' in results['kmeans']:\n",
    "            # Project centroids to 2D using the same PCA\n",
    "            centroids_2d = pca.transform(results['kmeans']['centroids'])\n",
    "            ax1.scatter(centroids_2d[:, 0], centroids_2d[:, 1], \n",
    "                       c='red', marker='x', s=200, linewidth=3, label='Centroids')\n",
    "        \n",
    "        ax1.set_title(f'K-Means Clustering\\n{dataset_name}\\n(k={results[\"kmeans\"][\"optimal_k\"]}, silhouette={results[\"kmeans\"][\"silhouette_score\"]:.3f})')\n",
    "        ax1.set_xlabel('First Component')\n",
    "        ax1.set_ylabel('Second Component')\n",
    "        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # DBSCAN visualization\n",
    "        dbscan_unique_labels = np.unique(dbscan_labels)\n",
    "        n_dbscan_clusters = len(dbscan_unique_labels[dbscan_unique_labels != -1])  # Exclude noise\n",
    "        \n",
    "        # Use a colormap for DBSCAN clusters\n",
    "        colors_dbscan = plt.cm.Set2(np.linspace(0, 1, max(n_dbscan_clusters, 1)))\n",
    "        \n",
    "        cluster_color_idx = 0  # Track color index for non-noise clusters\n",
    "        for label in dbscan_unique_labels:\n",
    "            mask = dbscan_labels == label\n",
    "            if label == -1:  # Noise points\n",
    "                ax2.scatter(X_2d[mask, 0], X_2d[mask, 1], \n",
    "                           c='red', s=50, alpha=0.6, marker='x', \n",
    "                           label='Noise', linewidth=1)\n",
    "            else:  # Cluster points\n",
    "                ax2.scatter(X_2d[mask, 0], X_2d[mask, 1], \n",
    "                           c=[colors_dbscan[cluster_color_idx]], s=50, alpha=0.7, \n",
    "                           label=f'Cluster {label}', edgecolors='black', linewidth=0.5)\n",
    "                cluster_color_idx += 1\n",
    "        \n",
    "        ax2.set_title(f'DBSCAN Clustering\\n{dataset_name}\\n(eps={results[\"dbscan\"][\"optimal_eps\"]:.3f}, min_samples={results[\"dbscan\"][\"optimal_min_samples\"]}, silhouette={results[\"dbscan\"][\"silhouette_score\"]:.3f})')\n",
    "        ax2.set_xlabel('First Component')\n",
    "        ax2.set_ylabel('Second Component')\n",
    "        ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add PCA information if used\n",
    "        fig.suptitle(f'Clustering Comparison: {dataset_name}\\n{pca_info}', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        filename = os.path.join(output_folder, f'6_clustering_visualization_{dataset_name.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")}.png')\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Clustering visualization for {dataset_name} saved to: {filename}\")\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b13ad118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_report(all_results, output_folder):\n",
    "    \n",
    "    report_path = os.path.join(output_folder, 'comparison.txt')\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "        f.write(\"COMPREHENSIVE COMPARISON: K-MEANS vs DBSCAN CLUSTERING\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "        \n",
    "        # Dataset overview\n",
    "        f.write(\"DATASET OVERVIEW\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        for dataset_name, results in all_results.items():\n",
    "            X_shape = results['X_scaled'].shape\n",
    "            f.write(f\"{dataset_name}:\\n\")\n",
    "            f.write(f\"  - Samples: {X_shape[0]}\\n\")\n",
    "            f.write(f\"  - Features: {X_shape[1]}\\n\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "        f.write(\"1. CLUSTER SIZE COMPARISON\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "        \n",
    "        for dataset_name, results in all_results.items():\n",
    "            f.write(f\"{dataset_name.upper()}\\n\")\n",
    "            f.write(\"-\" * len(dataset_name) + \"\\n\")\n",
    "            \n",
    "            kmeans_results = results['kmeans']\n",
    "            dbscan_results = results['dbscan']\n",
    "            \n",
    "            # K-means cluster sizes\n",
    "            f.write(f\"K-Means (k={kmeans_results['optimal_k']}):\\n\")\n",
    "            for i, size in enumerate(kmeans_results['cluster_sizes']):\n",
    "                percentage = (size / sum(kmeans_results['cluster_sizes'])) * 100\n",
    "                f.write(f\"  Cluster {i}: {size} points ({percentage:.1f}%)\\n\")\n",
    "            \n",
    "            f.write(f\"\\nDBSCAN (eps={dbscan_results['optimal_eps']:.3f}, min_samples={dbscan_results['optimal_min_samples']}):\\n\")\n",
    "            total_non_noise = sum(dbscan_results['cluster_sizes'])\n",
    "            total_points = total_non_noise + dbscan_results['n_noise']\n",
    "            \n",
    "            for i, size in enumerate(dbscan_results['cluster_sizes']):\n",
    "                percentage = (size / total_points) * 100\n",
    "                f.write(f\"  Cluster {i}: {size} points ({percentage:.1f}%)\\n\")\n",
    "            \n",
    "            if dbscan_results['n_noise'] > 0:\n",
    "                noise_percentage = (dbscan_results['n_noise'] / total_points) * 100\n",
    "                f.write(f\"  Noise: {dbscan_results['n_noise']} points ({noise_percentage:.1f}%)\\n\")\n",
    "            \n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "        f.write(\"2. SILHOUETTE SCORE COMPARISON\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "        \n",
    "        # Summary table\n",
    "        f.write(\"Algorithm Performance Summary:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        f.write(f\"{'Dataset':<20} {'K-Means':<15} {'DBSCAN':<15} {'Winner':<10}\\n\")\n",
    "        f.write(\"-\" * 65 + \"\\n\")\n",
    "        \n",
    "        kmeans_wins = 0\n",
    "        dbscan_wins = 0\n",
    "        \n",
    "        for dataset_name, results in all_results.items():\n",
    "            kmeans_sil = results['kmeans']['silhouette_score']\n",
    "            dbscan_sil = results['dbscan']['silhouette_score']\n",
    "            \n",
    "            if kmeans_sil > dbscan_sil:\n",
    "                winner = \"K-Means\"\n",
    "                kmeans_wins += 1\n",
    "            elif dbscan_sil > kmeans_sil:\n",
    "                winner = \"DBSCAN\"\n",
    "                dbscan_wins += 1\n",
    "            else:\n",
    "                winner = \"Tie\"\n",
    "            \n",
    "            f.write(f\"{dataset_name:<20} {kmeans_sil:<15.4f} {dbscan_sil:<15.4f} {winner:<10}\\n\")\n",
    "        \n",
    "        f.write(\"-\" * 65 + \"\\n\")\n",
    "        f.write(f\"Total Wins: K-Means={kmeans_wins}, DBSCAN={dbscan_wins}\\n\\n\")\n",
    "        \n",
    "        # Detailed analysis\n",
    "        f.write(\"Detailed Analysis:\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        for dataset_name, results in all_results.items():\n",
    "            f.write(f\"\\n{dataset_name}:\\n\")\n",
    "            \n",
    "            kmeans_results = results['kmeans']\n",
    "            dbscan_results = results['dbscan']\n",
    "            \n",
    "            f.write(f\"  K-Means:\\n\")\n",
    "            f.write(f\"    - Optimal k: {kmeans_results['optimal_k']}\\n\")\n",
    "            f.write(f\"    - Silhouette Score: {kmeans_results['silhouette_score']:.4f}\\n\")\n",
    "            f.write(f\"    - Inertia: {kmeans_results['inertia']:.4f}\\n\")\n",
    "            f.write(f\"    - All points clustered (no noise concept)\\n\")\n",
    "            \n",
    "            f.write(f\"  DBSCAN:\\n\")\n",
    "            f.write(f\"    - Optimal eps: {dbscan_results['optimal_eps']:.4f}\\n\")\n",
    "            f.write(f\"    - Optimal min_samples: {dbscan_results['optimal_min_samples']}\\n\")\n",
    "            f.write(f\"    - Silhouette Score: {dbscan_results['silhouette_score']:.4f}\\n\")\n",
    "            f.write(f\"    - Number of clusters: {dbscan_results['n_clusters']}\\n\")\n",
    "            f.write(f\"    - Noise ratio: {dbscan_results['noise_ratio']:.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "        f.write(\"3. ALGORITHM CHARACTERISTICS SUMMARY\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"K-Means Characteristics:\\n\")\n",
    "        f.write(\"- Requires pre-specification of number of clusters (k)\\n\")\n",
    "        f.write(\"- Assumes spherical clusters of similar size\\n\")\n",
    "        f.write(\"- Every point is assigned to a cluster (no noise concept)\\n\")\n",
    "        f.write(\"- Sensitive to initialization (uses k-means++ here)\\n\")\n",
    "        f.write(\"- Computationally efficient\\n\")\n",
    "        f.write(\"- Works well with well-separated, spherical clusters\\n\\n\")\n",
    "        \n",
    "        f.write(\"DBSCAN Characteristics:\\n\")\n",
    "        f.write(\"- Automatically determines number of clusters\\n\")\n",
    "        f.write(\"- Can find clusters of arbitrary shape\\n\")\n",
    "        f.write(\"- Identifies noise/outlier points\\n\")\n",
    "        f.write(\"- Requires tuning of eps and min_samples parameters\\n\")\n",
    "        f.write(\"- More robust to outliers\\n\")\n",
    "        f.write(\"- Works well with non-spherical clusters and varying densities\\n\\n\")\n",
    "        \n",
    "        # Recommendations\n",
    "        f.write(\"RECOMMENDATIONS:\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        best_overall_kmeans = sum(results['kmeans']['silhouette_score'] for results in all_results.values()) / len(all_results)\n",
    "        best_overall_dbscan = sum(results['dbscan']['silhouette_score'] for results in all_results.values()) / len(all_results)\n",
    "        \n",
    "        f.write(f\"Average Silhouette Scores:\\n\")\n",
    "        f.write(f\"- K-Means: {best_overall_kmeans:.4f}\\n\")\n",
    "        f.write(f\"- DBSCAN: {best_overall_dbscan:.4f}\\n\\n\")\n",
    "        \n",
    "        if best_overall_kmeans > best_overall_dbscan:\n",
    "            f.write(\"Overall Recommendation: K-Means performs better on average across all datasets.\\n\")\n",
    "        else:\n",
    "            f.write(\"Overall Recommendation: DBSCAN performs better on average across all datasets.\\n\")\n",
    "        \n",
    "        f.write(\"\\nDataset-specific recommendations:\\n\")\n",
    "        for dataset_name, results in all_results.items():\n",
    "            kmeans_sil = results['kmeans']['silhouette_score']\n",
    "            dbscan_sil = results['dbscan']['silhouette_score']\n",
    "            \n",
    "            if kmeans_sil > dbscan_sil:\n",
    "                f.write(f\"- {dataset_name}: Use K-Means (silhouette: {kmeans_sil:.4f} vs {dbscan_sil:.4f})\\n\")\n",
    "            else:\n",
    "                f.write(f\"- {dataset_name}: Use DBSCAN (silhouette: {dbscan_sil:.4f} vs {kmeans_sil:.4f})\\n\")\n",
    "    \n",
    "    print(f\"Comparison report saved to: {report_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd1e3c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the comprehensive comparison.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPREHENSIVE CLUSTERING COMPARISON: K-MEANS vs DBSCAN\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create output folder\n",
    "    output_folder = create_output_folder()\n",
    "    \n",
    "    # Load datasets configuration\n",
    "    try:\n",
    "        with open('dataset.json', 'r') as f:\n",
    "            datasets_config = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\" dataset.json file not found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nLoading {len(datasets_config)} datasets for comparison...\")\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    # Process each dataset\n",
    "    for dataset_name, dataset_id in datasets_config.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {dataset_name} (ID: {dataset_id})\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Load dataset\n",
    "        X, y, feature_names, actual_name = load_dataset_by_id(dataset_id)\n",
    "        \n",
    "        if X is None:\n",
    "            print(f\"Skipping {dataset_name} due to loading error\")\n",
    "            continue\n",
    "        \n",
    "        # Use actual dataset name if available\n",
    "        display_name = actual_name if actual_name else dataset_name\n",
    "        \n",
    "        # Preprocess data\n",
    "        print(\"Preprocessing data...\")\n",
    "        X_scaled, scaler, valid_indices = preprocess_data(X)\n",
    "        \n",
    "        if X_scaled.shape[0] < 10:\n",
    "            print(f\" Dataset {display_name} has too few samples after preprocessing, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Run K-means analysis\n",
    "        kmeans_results = run_kmeans_analysis(X_scaled, display_name)\n",
    "        \n",
    "        # Run DBSCAN analysis\n",
    "        dbscan_results = run_dbscan_analysis(X_scaled, display_name)\n",
    "        \n",
    "        # Store results\n",
    "        all_results[display_name] = {\n",
    "            'kmeans': kmeans_results,\n",
    "            'dbscan': dbscan_results,\n",
    "            'X_scaled': X_scaled,\n",
    "            'original_shape': X.shape,\n",
    "            'feature_names': feature_names\n",
    "        }\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\" No datasets were successfully processed!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"GENERATING COMPARISON VISUALIZATIONS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Generate all comparison plots\n",
    "    print(\"\\n1. Creating elbow method comparison...\")\n",
    "    plot_elbow_method_comparison(all_results, output_folder)\n",
    "    \n",
    "    print(\"\\n2. Creating silhouette analysis comparisons...\")\n",
    "    plot_silhouette_comparison_per_dataset(all_results, output_folder)\n",
    "    \n",
    "    print(\"\\n3. Creating cluster size comparisons...\")\n",
    "    plot_cluster_size_comparison_per_dataset(all_results, output_folder)\n",
    "    \n",
    "    print(\"\\n4. Creating silhouette score by parameters plots...\")\n",
    "    plot_silhouette_score_by_parameters(all_results, output_folder)\n",
    "    \n",
    "    print(\"\\n5. Creating noise ratio by parameters plots...\")\n",
    "    plot_noise_ratio_by_parameters(all_results, output_folder)\n",
    "    \n",
    "    print(\"\\n6. Creating clustering visualizations...\")\n",
    "    plot_clustering_visualizations(all_results, output_folder)\n",
    "    \n",
    "    print(\"\\n7. Creating comprehensive text report...\")\n",
    "    create_comparison_report(all_results, output_folder)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3af2bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE CLUSTERING COMPARISON: K-MEANS vs DBSCAN\n",
      "================================================================================\n",
      "Using existing output folder: comparison\n",
      "\n",
      "Loading 10 datasets for comparison...\n",
      "\n",
      "============================================================\n",
      "Processing: iris (ID: 53)\n",
      "============================================================\n",
      "Loading dataset ID: 53\n",
      " Loaded Iris: 150 samples, 4 features\n",
      "Preprocessing data...\n",
      "Data preprocessing completed.\n",
      "Running K-means analysis for Iris...\n",
      "Finding optimal number of clusters (k=1 to 10)...\n",
      "Testing k=1...\n",
      "Converged after 2 iterations\n",
      "Testing k=2...\n",
      "Converged after 6 iterations\n",
      "Testing k=3...\n",
      "Converged after 6 iterations\n",
      "Testing k=4...\n",
      "Converged after 14 iterations\n",
      "Testing k=5...\n",
      "Converged after 7 iterations\n",
      "Testing k=6...\n",
      "Converged after 8 iterations\n",
      "Testing k=7...\n",
      "Converged after 8 iterations\n",
      "Testing k=8...\n",
      "Converged after 5 iterations\n",
      "Testing k=9...\n",
      "Converged after 11 iterations\n",
      "Testing k=10...\n",
      "Converged after 11 iterations\n",
      "Converged after 6 iterations\n",
      "   K-means: k=3, silhouette=0.456\n",
      "Running DBSCAN analysis for Iris...\n",
      "   Using 20 parameter combinations for 150 samples\n",
      "  - Computing k-distance graph for epsilon range selection...\n",
      "  - epsilon range: 0.435 to 0.676\n",
      "  - min_samples range: 2 to 7\n",
      "Testing combination 1/20: epsilon=0.435, min_samples=2\n",
      "Testing combination 2/20: epsilon=0.435, min_samples=4\n",
      "Testing combination 3/20: epsilon=0.435, min_samples=6\n",
      "Testing combination 4/20: epsilon=0.469, min_samples=2\n",
      "Testing combination 5/20: epsilon=0.469, min_samples=4\n",
      "Testing combination 6/20: epsilon=0.469, min_samples=6\n",
      "Testing combination 7/20: epsilon=0.504, min_samples=2\n",
      "Testing combination 8/20: epsilon=0.504, min_samples=4\n",
      "Testing combination 9/20: epsilon=0.504, min_samples=6\n",
      "Testing combination 10/20: epsilon=0.538, min_samples=2\n",
      "Testing combination 11/20: epsilon=0.538, min_samples=4\n",
      "Testing combination 12/20: epsilon=0.538, min_samples=6\n",
      "Testing combination 13/20: epsilon=0.573, min_samples=2\n",
      "Testing combination 14/20: epsilon=0.573, min_samples=4\n",
      "Testing combination 15/20: epsilon=0.573, min_samples=6\n",
      "Testing combination 16/20: epsilon=0.607, min_samples=2\n",
      "Testing combination 17/20: epsilon=0.607, min_samples=4\n",
      "Testing combination 18/20: epsilon=0.607, min_samples=6\n",
      "Testing combination 19/20: epsilon=0.642, min_samples=2\n",
      "Testing combination 20/20: epsilon=0.642, min_samples=4\n",
      "\n",
      "Top 5 parameter combinations:\n",
      "  1. epsilon=0.642, min_samples=4, clusters=2, noise=0.067, silhouette=0.618, score=0.597\n",
      "  2. epsilon=0.607, min_samples=4, clusters=2, noise=0.120, silhouette=0.632, score=0.594\n",
      "  3. epsilon=0.573, min_samples=4, clusters=2, noise=0.153, silhouette=0.639, score=0.590\n",
      "  4. epsilon=0.538, min_samples=4, clusters=2, noise=0.187, silhouette=0.646, score=0.585\n",
      "  5. epsilon=0.607, min_samples=6, clusters=2, noise=0.180, silhouette=0.642, score=0.584\n",
      "   DBSCAN: clusters=2, noise_ratio=0.067, silhouette=0.618\n",
      "\n",
      "============================================================\n",
      "Processing: wine (ID: 109)\n",
      "============================================================\n",
      "Loading dataset ID: 109\n",
      " Loaded Wine: 178 samples, 13 features\n",
      "Preprocessing data...\n",
      "Data preprocessing completed.\n",
      "Running K-means analysis for Wine...\n",
      "Finding optimal number of clusters (k=1 to 10)...\n",
      "Testing k=1...\n",
      "Converged after 2 iterations\n",
      "Testing k=2...\n",
      "Converged after 7 iterations\n",
      "Testing k=3...\n",
      "Converged after 5 iterations\n",
      "Testing k=4...\n",
      "Converged after 5 iterations\n",
      "Testing k=5...\n",
      "Converged after 8 iterations\n",
      "Testing k=6...\n",
      "Converged after 18 iterations\n",
      "Testing k=7...\n",
      "Converged after 7 iterations\n",
      "Testing k=8...\n",
      "Converged after 5 iterations\n",
      "Testing k=9...\n",
      "Converged after 5 iterations\n",
      "Testing k=10...\n",
      "Converged after 6 iterations\n",
      "Converged after 5 iterations\n",
      "   K-means: k=3, silhouette=0.284\n",
      "Running DBSCAN analysis for Wine...\n",
      "   Using 20 parameter combinations for 178 samples\n",
      "  - Computing k-distance graph for epsilon range selection...\n",
      "  - epsilon range: 2.071 to 2.679\n",
      "  - min_samples range: 6 to 8\n",
      "Testing combination 1/20: epsilon=2.071, min_samples=6\n",
      "Testing combination 2/20: epsilon=2.071, min_samples=7\n",
      "Testing combination 3/20: epsilon=2.071, min_samples=8\n",
      "Testing combination 4/20: epsilon=2.158, min_samples=6\n",
      "Testing combination 5/20: epsilon=2.158, min_samples=7\n",
      "Testing combination 6/20: epsilon=2.158, min_samples=8\n",
      "Testing combination 7/20: epsilon=2.245, min_samples=6\n",
      "Testing combination 8/20: epsilon=2.245, min_samples=7\n",
      "Testing combination 9/20: epsilon=2.245, min_samples=8\n",
      "Testing combination 10/20: epsilon=2.332, min_samples=6\n",
      "Testing combination 11/20: epsilon=2.332, min_samples=7\n",
      "Testing combination 12/20: epsilon=2.332, min_samples=8\n",
      "Testing combination 13/20: epsilon=2.419, min_samples=6\n",
      "Testing combination 14/20: epsilon=2.419, min_samples=7\n",
      "Testing combination 15/20: epsilon=2.419, min_samples=8\n",
      "Testing combination 16/20: epsilon=2.505, min_samples=6\n",
      "Testing combination 17/20: epsilon=2.505, min_samples=7\n",
      "Testing combination 18/20: epsilon=2.505, min_samples=8\n",
      "Testing combination 19/20: epsilon=2.592, min_samples=6\n",
      "Testing combination 20/20: epsilon=2.592, min_samples=7\n",
      "\n",
      "Top 5 parameter combinations:\n",
      "  1. epsilon=2.245, min_samples=8, clusters=2, noise=0.343, silhouette=0.356, score=0.295\n",
      "  2. epsilon=2.419, min_samples=7, clusters=2, noise=0.219, silhouette=0.330, score=0.294\n",
      "  3. epsilon=2.245, min_samples=7, clusters=2, noise=0.320, silhouette=0.350, score=0.294\n",
      "  4. epsilon=2.245, min_samples=6, clusters=2, noise=0.292, silhouette=0.344, score=0.293\n",
      "  5. epsilon=2.419, min_samples=8, clusters=2, noise=0.225, silhouette=0.330, score=0.293\n",
      "   DBSCAN: clusters=2, noise_ratio=0.343, silhouette=0.356\n",
      "\n",
      "============================================================\n",
      "Processing: wholesale (ID: 292)\n",
      "============================================================\n",
      "Loading dataset ID: 292\n",
      " Loaded Wholesale customers: 440 samples, 7 features\n",
      "Preprocessing data...\n",
      "Data preprocessing completed.\n",
      "Running K-means analysis for Wholesale customers...\n",
      "Finding optimal number of clusters (k=1 to 10)...\n",
      "Testing k=1...\n",
      "Converged after 2 iterations\n",
      "Testing k=2...\n",
      "Converged after 2 iterations\n",
      "Testing k=3...\n",
      "Converged after 6 iterations\n",
      "Testing k=4...\n",
      "Converged after 10 iterations\n",
      "Testing k=5...\n",
      "Converged after 8 iterations\n",
      "Testing k=6...\n",
      "Converged after 8 iterations\n",
      "Testing k=7...\n",
      "Converged after 8 iterations\n",
      "Testing k=8...\n",
      "Converged after 6 iterations\n",
      "Testing k=9...\n",
      "Converged after 12 iterations\n",
      "Testing k=10...\n",
      "Converged after 12 iterations\n",
      "Converged after 6 iterations\n",
      "   K-means: k=3, silhouette=0.450\n",
      "Running DBSCAN analysis for Wholesale customers...\n",
      "   Using 20 parameter combinations for 440 samples\n",
      "  - Computing k-distance graph for epsilon range selection...\n",
      "  - epsilon range: 0.369 to 0.908\n",
      "  - min_samples range: 3 to 14\n",
      "Testing combination 1/20: epsilon=0.369, min_samples=3\n",
      "Testing combination 2/20: epsilon=0.369, min_samples=7\n",
      "Testing combination 3/20: epsilon=0.369, min_samples=11\n",
      "Testing combination 4/20: epsilon=0.446, min_samples=3\n",
      "Testing combination 5/20: epsilon=0.446, min_samples=7\n",
      "Testing combination 6/20: epsilon=0.446, min_samples=11\n",
      "Testing combination 7/20: epsilon=0.523, min_samples=3\n",
      "Testing combination 8/20: epsilon=0.523, min_samples=7\n",
      "Testing combination 9/20: epsilon=0.523, min_samples=11\n",
      "Testing combination 10/20: epsilon=0.600, min_samples=3\n",
      "Testing combination 11/20: epsilon=0.600, min_samples=7\n",
      "Testing combination 12/20: epsilon=0.600, min_samples=11\n",
      "Testing combination 13/20: epsilon=0.677, min_samples=3\n",
      "Testing combination 14/20: epsilon=0.677, min_samples=7\n",
      "Testing combination 15/20: epsilon=0.677, min_samples=11\n",
      "Testing combination 16/20: epsilon=0.754, min_samples=3\n",
      "Testing combination 17/20: epsilon=0.754, min_samples=7\n",
      "Testing combination 18/20: epsilon=0.754, min_samples=11\n",
      "Testing combination 19/20: epsilon=0.831, min_samples=3\n",
      "Testing combination 20/20: epsilon=0.831, min_samples=7\n",
      "\n",
      "Top 5 parameter combinations:\n",
      "  1. epsilon=0.754, min_samples=7, clusters=2, noise=0.241, silhouette=0.564, score=0.496\n",
      "  2. epsilon=0.831, min_samples=7, clusters=2, noise=0.193, silhouette=0.547, score=0.494\n",
      "  3. epsilon=0.677, min_samples=11, clusters=2, noise=0.352, silhouette=0.593, score=0.488\n",
      "  4. epsilon=0.600, min_samples=7, clusters=2, noise=0.373, silhouette=0.598, score=0.486\n",
      "  5. epsilon=0.754, min_samples=11, clusters=2, noise=0.300, silhouette=0.572, score=0.486\n",
      "   DBSCAN: clusters=2, noise_ratio=0.241, silhouette=0.564\n",
      "\n",
      "============================================================\n",
      "Processing: heart_disease (ID: 45)\n",
      "============================================================\n",
      "Loading dataset ID: 45\n",
      " Loaded Heart Disease: 303 samples, 13 features\n",
      "Preprocessing data...\n",
      "Data preprocessing completed.\n",
      "Running K-means analysis for Heart Disease...\n",
      "Finding optimal number of clusters (k=1 to 10)...\n",
      "Testing k=1...\n",
      "Converged after 2 iterations\n",
      "Testing k=2...\n",
      "Converged after 7 iterations\n",
      "Testing k=3...\n",
      "Converged after 6 iterations\n",
      "Testing k=4...\n",
      "Converged after 6 iterations\n",
      "Testing k=5...\n",
      "Converged after 10 iterations\n",
      "Testing k=6...\n",
      "Converged after 14 iterations\n",
      "Testing k=7...\n",
      "Converged after 16 iterations\n",
      "Testing k=8...\n",
      "Converged after 16 iterations\n",
      "Testing k=9...\n",
      "Converged after 13 iterations\n",
      "Testing k=10...\n",
      "Converged after 16 iterations\n",
      "Converged after 6 iterations\n",
      "   K-means: k=4, silhouette=0.131\n",
      "Running DBSCAN analysis for Heart Disease...\n",
      "   Using 20 parameter combinations for 297 samples\n",
      "  - Computing k-distance graph for epsilon range selection...\n",
      "  - epsilon range: 2.317 to 3.200\n",
      "  - min_samples range: 6 to 14\n",
      "Testing combination 1/20: epsilon=2.317, min_samples=6\n",
      "Testing combination 2/20: epsilon=2.317, min_samples=9\n",
      "Testing combination 3/20: epsilon=2.317, min_samples=12\n",
      "Testing combination 4/20: epsilon=2.443, min_samples=6\n",
      "Testing combination 5/20: epsilon=2.443, min_samples=9\n",
      "Testing combination 6/20: epsilon=2.443, min_samples=12\n",
      "Testing combination 7/20: epsilon=2.569, min_samples=6\n",
      "Testing combination 8/20: epsilon=2.569, min_samples=9\n",
      "Testing combination 9/20: epsilon=2.569, min_samples=12\n",
      "Testing combination 10/20: epsilon=2.695, min_samples=6\n",
      "Testing combination 11/20: epsilon=2.695, min_samples=9\n",
      "Testing combination 12/20: epsilon=2.695, min_samples=12\n",
      "Testing combination 13/20: epsilon=2.821, min_samples=6\n",
      "Testing combination 14/20: epsilon=2.821, min_samples=9\n",
      "Testing combination 15/20: epsilon=2.821, min_samples=12\n",
      "Testing combination 16/20: epsilon=2.948, min_samples=6\n",
      "Testing combination 17/20: epsilon=2.948, min_samples=9\n",
      "Testing combination 18/20: epsilon=2.948, min_samples=12\n",
      "Testing combination 19/20: epsilon=3.074, min_samples=6\n",
      "Testing combination 20/20: epsilon=3.074, min_samples=9\n",
      "\n",
      "Top 5 parameter combinations:\n",
      "  1. epsilon=2.317, min_samples=9, clusters=2, noise=0.667, silhouette=0.392, score=0.261\n",
      "  2. epsilon=2.443, min_samples=12, clusters=2, noise=0.616, silhouette=0.366, score=0.253\n",
      "  3. epsilon=2.569, min_samples=12, clusters=2, noise=0.522, silhouette=0.289, score=0.213\n",
      "  4. epsilon=2.569, min_samples=9, clusters=2, noise=0.481, silhouette=0.262, score=0.199\n",
      "  5. epsilon=2.695, min_samples=12, clusters=2, noise=0.401, silhouette=0.236, score=0.189\n",
      "   DBSCAN: clusters=2, noise_ratio=0.667, silhouette=0.392\n",
      "\n",
      "============================================================\n",
      "Processing: heart_failure (ID: 519)\n",
      "============================================================\n",
      "Loading dataset ID: 519\n",
      " Loaded Heart Failure Clinical Records: 299 samples, 12 features\n",
      "Preprocessing data...\n",
      "Data preprocessing completed.\n",
      "Running K-means analysis for Heart Failure Clinical Records...\n",
      "Finding optimal number of clusters (k=1 to 10)...\n",
      "Testing k=1...\n",
      "Converged after 2 iterations\n",
      "Testing k=2...\n",
      "Converged after 7 iterations\n",
      "Testing k=3...\n",
      "Converged after 8 iterations\n",
      "Testing k=4...\n",
      "Converged after 13 iterations\n",
      "Testing k=5...\n",
      "Converged after 22 iterations\n",
      "Testing k=6...\n",
      "Converged after 21 iterations\n",
      "Testing k=7...\n",
      "Converged after 14 iterations\n",
      "Testing k=8...\n",
      "Converged after 17 iterations\n",
      "Testing k=9...\n",
      "Converged after 9 iterations\n",
      "Testing k=10...\n",
      "Converged after 19 iterations\n",
      "Converged after 13 iterations\n",
      "   K-means: k=4, silhouette=0.096\n",
      "Running DBSCAN analysis for Heart Failure Clinical Records...\n",
      "   Using 20 parameter combinations for 299 samples\n",
      "  - Computing k-distance graph for epsilon range selection...\n",
      "  - epsilon range: 2.285 to 2.902\n",
      "  - min_samples range: 6 to 14\n",
      "Testing combination 1/20: epsilon=2.285, min_samples=6\n",
      "Testing combination 2/20: epsilon=2.285, min_samples=9\n",
      "Testing combination 3/20: epsilon=2.285, min_samples=12\n",
      "Testing combination 4/20: epsilon=2.373, min_samples=6\n",
      "Testing combination 5/20: epsilon=2.373, min_samples=9\n",
      "Testing combination 6/20: epsilon=2.373, min_samples=12\n",
      "Testing combination 7/20: epsilon=2.461, min_samples=6\n",
      "Testing combination 8/20: epsilon=2.461, min_samples=9\n",
      "Testing combination 9/20: epsilon=2.461, min_samples=12\n",
      "Testing combination 10/20: epsilon=2.549, min_samples=6\n",
      "Testing combination 11/20: epsilon=2.549, min_samples=9\n",
      "Testing combination 12/20: epsilon=2.549, min_samples=12\n",
      "Testing combination 13/20: epsilon=2.637, min_samples=6\n",
      "Testing combination 14/20: epsilon=2.637, min_samples=9\n",
      "Testing combination 15/20: epsilon=2.637, min_samples=12\n",
      "Testing combination 16/20: epsilon=2.726, min_samples=6\n",
      "Testing combination 17/20: epsilon=2.726, min_samples=9\n",
      "Testing combination 18/20: epsilon=2.726, min_samples=12\n",
      "Testing combination 19/20: epsilon=2.814, min_samples=6\n",
      "Testing combination 20/20: epsilon=2.814, min_samples=9\n",
      "\n",
      "Top 5 parameter combinations:\n",
      "  1. epsilon=2.373, min_samples=12, clusters=2, noise=0.853, silhouette=0.267, score=0.153\n",
      "  2. epsilon=2.285, min_samples=9, clusters=4, noise=0.783, silhouette=0.238, score=0.145\n",
      "  3. epsilon=2.373, min_samples=9, clusters=2, noise=0.532, silhouette=0.183, score=0.135\n",
      "  4. epsilon=2.285, min_samples=12, clusters=2, noise=0.903, silhouette=0.241, score=0.132\n",
      "  5. epsilon=2.461, min_samples=12, clusters=3, noise=0.629, silhouette=0.125, score=0.086\n",
      "   DBSCAN: clusters=2, noise_ratio=0.853, silhouette=0.267\n",
      "\n",
      "============================================================\n",
      "Processing: energy (ID: 242)\n",
      "============================================================\n",
      "Loading dataset ID: 242\n",
      " Loaded Energy Efficiency: 768 samples, 8 features\n",
      "Preprocessing data...\n",
      "Data preprocessing completed.\n",
      "Running K-means analysis for Energy Efficiency...\n",
      "Finding optimal number of clusters (k=1 to 10)...\n",
      "Testing k=1...\n",
      "Converged after 2 iterations\n",
      "Testing k=2...\n",
      "Converged after 3 iterations\n",
      "Testing k=3...\n",
      "Converged after 16 iterations\n",
      "Testing k=4...\n",
      "Converged after 16 iterations\n",
      "Testing k=5...\n",
      "Converged after 18 iterations\n",
      "Testing k=6...\n",
      "Converged after 18 iterations\n",
      "Testing k=7...\n",
      "Converged after 15 iterations\n",
      "Testing k=8...\n",
      "Converged after 24 iterations\n",
      "Testing k=9...\n",
      "Converged after 24 iterations\n",
      "Testing k=10...\n",
      "Converged after 24 iterations\n",
      "Converged after 3 iterations\n",
      "   K-means: k=2, silhouette=0.391\n",
      "Running DBSCAN analysis for Energy Efficiency...\n",
      "   Using 20 parameter combinations for 768 samples\n",
      "  - Computing k-distance graph for epsilon range selection...\n",
      "  - epsilon range: 0.919 to 1.103\n",
      "  - min_samples range: 4 to 16\n",
      "Testing combination 1/20: epsilon=0.919, min_samples=4\n",
      "Testing combination 2/20: epsilon=0.919, min_samples=9\n",
      "Testing combination 3/20: epsilon=0.919, min_samples=14\n",
      "Testing combination 4/20: epsilon=0.946, min_samples=6\n",
      "Testing combination 5/20: epsilon=0.946, min_samples=11\n",
      "Testing combination 6/20: epsilon=0.946, min_samples=16\n",
      "Testing combination 7/20: epsilon=0.972, min_samples=8\n",
      "Testing combination 8/20: epsilon=0.972, min_samples=13\n",
      "Testing combination 9/20: epsilon=0.998, min_samples=5\n",
      "Testing combination 10/20: epsilon=0.998, min_samples=10\n",
      "Testing combination 11/20: epsilon=0.998, min_samples=15\n",
      "Testing combination 12/20: epsilon=1.024, min_samples=7\n",
      "Testing combination 13/20: epsilon=1.024, min_samples=12\n",
      "Testing combination 14/20: epsilon=1.050, min_samples=4\n",
      "Testing combination 15/20: epsilon=1.050, min_samples=9\n",
      "Testing combination 16/20: epsilon=1.050, min_samples=14\n",
      "Testing combination 17/20: epsilon=1.077, min_samples=6\n",
      "Testing combination 18/20: epsilon=1.077, min_samples=11\n",
      "Testing combination 19/20: epsilon=1.077, min_samples=16\n",
      "Testing combination 20/20: epsilon=1.103, min_samples=8\n",
      "\n",
      "Top 5 parameter combinations:\n",
      "  1. epsilon=0.919, min_samples=9, clusters=6, noise=0.883, silhouette=0.244, score=0.137\n",
      "  2. epsilon=0.919, min_samples=4, clusters=14, noise=0.010, silhouette=0.114, score=0.114\n",
      "  3. epsilon=1.103, min_samples=8, clusters=12, noise=0.021, silhouette=0.108, score=0.107\n",
      "  4. epsilon=1.077, min_samples=11, clusters=6, noise=0.531, silhouette=0.144, score=0.106\n",
      "  5. epsilon=0.946, min_samples=6, clusters=6, noise=0.234, silhouette=0.118, score=0.105\n",
      "   DBSCAN: clusters=6, noise_ratio=0.883, silhouette=0.244\n",
      "\n",
      "============================================================\n",
      "Processing: credit (ID: 27)\n",
      "============================================================\n",
      "Loading dataset ID: 27\n",
      "\n",
      " Categorical features detected:\n",
      "   - A13\n",
      "   - A12\n",
      "   - A10\n",
      "   - A9\n",
      "   - A7\n",
      "   - A6\n",
      "   - A5\n",
      "   - A4\n",
      "   - A1\n",
      "\n",
      " Keeping 6 numerical features for clustering:\n",
      "   - A15\n",
      "   - A14\n",
      "   - A11\n",
      "   - A8\n",
      "   - A3\n",
      "   - A2\n",
      " Loaded Credit Approval: 690 samples, 6 features\n",
      "   Removed 9 categorical features\n",
      "Preprocessing data...\n",
      "Data preprocessing completed.\n",
      "Running K-means analysis for Credit Approval...\n",
      "Finding optimal number of clusters (k=1 to 10)...\n",
      "Testing k=1...\n",
      "Converged after 2 iterations\n",
      "Testing k=2...\n",
      "Converged after 10 iterations\n",
      "Testing k=3...\n",
      "Converged after 8 iterations\n",
      "Testing k=4...\n",
      "Converged after 12 iterations\n",
      "Testing k=5...\n",
      "Converged after 8 iterations\n",
      "Testing k=6...\n",
      "Converged after 13 iterations\n",
      "Testing k=7...\n",
      "Converged after 18 iterations\n",
      "Testing k=8...\n",
      "Converged after 13 iterations\n",
      "Testing k=9...\n",
      "Converged after 14 iterations\n",
      "Testing k=10...\n",
      "Converged after 14 iterations\n",
      "Converged after 13 iterations\n",
      "   K-means: k=6, silhouette=0.262\n",
      "Running DBSCAN analysis for Credit Approval...\n",
      "   Using 20 parameter combinations for 666 samples\n",
      "  - Computing k-distance graph for epsilon range selection...\n",
      "  - epsilon range: 0.433 to 1.139\n",
      "  - min_samples range: 3 to 12\n",
      "Testing combination 1/20: epsilon=0.433, min_samples=3\n",
      "Testing combination 2/20: epsilon=0.433, min_samples=7\n",
      "Testing combination 3/20: epsilon=0.433, min_samples=11\n",
      "Testing combination 4/20: epsilon=0.534, min_samples=5\n",
      "Testing combination 5/20: epsilon=0.534, min_samples=9\n",
      "Testing combination 6/20: epsilon=0.635, min_samples=3\n",
      "Testing combination 7/20: epsilon=0.635, min_samples=7\n",
      "Testing combination 8/20: epsilon=0.635, min_samples=11\n",
      "Testing combination 9/20: epsilon=0.735, min_samples=5\n",
      "Testing combination 10/20: epsilon=0.735, min_samples=9\n",
      "Testing combination 11/20: epsilon=0.836, min_samples=3\n",
      "Testing combination 12/20: epsilon=0.836, min_samples=7\n",
      "Testing combination 13/20: epsilon=0.836, min_samples=11\n",
      "Testing combination 14/20: epsilon=0.937, min_samples=5\n",
      "Testing combination 15/20: epsilon=0.937, min_samples=9\n",
      "Testing combination 16/20: epsilon=1.038, min_samples=3\n",
      "Testing combination 17/20: epsilon=1.038, min_samples=7\n",
      "Testing combination 18/20: epsilon=1.038, min_samples=11\n",
      "Testing combination 19/20: epsilon=1.139, min_samples=5\n",
      "Testing combination 20/20: epsilon=1.139, min_samples=9\n",
      "\n",
      "Top 5 parameter combinations:\n",
      "  1. epsilon=1.139, min_samples=5, clusters=2, noise=0.156, silhouette=0.380, score=0.350\n",
      "  2. epsilon=0.433, min_samples=11, clusters=2, noise=0.704, silhouette=0.528, score=0.342\n",
      "  3. epsilon=0.735, min_samples=5, clusters=2, noise=0.324, silhouette=0.361, score=0.303\n",
      "  4. epsilon=0.937, min_samples=5, clusters=2, noise=0.218, silhouette=0.330, score=0.294\n",
      "  5. epsilon=1.038, min_samples=3, clusters=4, noise=0.150, silhouette=0.286, score=0.265\n",
      "   DBSCAN: clusters=2, noise_ratio=0.156, silhouette=0.380\n",
      "\n",
      "============================================================\n",
      "Processing: kidney (ID: 336)\n",
      "============================================================\n",
      "Loading dataset ID: 336\n",
      "\n",
      " Categorical features detected:\n",
      "   - rbc\n",
      "   - pc\n",
      "   - pcc\n",
      "   - ba\n",
      "   - htn\n",
      "   - dm\n",
      "   - cad\n",
      "   - appet\n",
      "   - pe\n",
      "   - ane\n",
      "\n",
      " Keeping 14 numerical features for clustering:\n",
      "   - age\n",
      "   - bp\n",
      "   - sg\n",
      "   - al\n",
      "   - su\n",
      "   - bgr\n",
      "   - bu\n",
      "   - sc\n",
      "   - sod\n",
      "   - pot\n",
      "   - hemo\n",
      "   - pcv\n",
      "   - wbcc\n",
      "   - rbcc\n",
      " Loaded Chronic Kidney Disease: 400 samples, 14 features\n",
      "   Removed 10 categorical features\n",
      "Preprocessing data...\n",
      "Data preprocessing completed.\n",
      "Running K-means analysis for Chronic Kidney Disease...\n",
      "Finding optimal number of clusters (k=1 to 10)...\n",
      "Testing k=1...\n",
      "Converged after 2 iterations\n",
      "Testing k=2...\n",
      "Converged after 8 iterations\n",
      "Testing k=3...\n",
      "Converged after 4 iterations\n",
      "Testing k=4...\n",
      "Converged after 15 iterations\n",
      "Testing k=5...\n",
      "Converged after 12 iterations\n",
      "Testing k=6...\n",
      "Converged after 11 iterations\n",
      "Testing k=7...\n",
      "Converged after 9 iterations\n",
      "Testing k=8...\n",
      "Converged after 11 iterations\n",
      "Testing k=9...\n",
      "Converged after 9 iterations\n",
      "Testing k=10...\n",
      "Converged after 5 iterations\n",
      "Converged after 4 iterations\n",
      "   K-means: k=3, silhouette=0.381\n",
      "Running DBSCAN analysis for Chronic Kidney Disease...\n",
      "   Using 20 parameter combinations for 203 samples\n",
      "  - Computing k-distance graph for epsilon range selection...\n",
      "  - epsilon range: 1.529 to 2.961\n",
      "  - min_samples range: 7 to 10\n",
      "Testing combination 1/20: epsilon=1.529, min_samples=7\n",
      "Testing combination 2/20: epsilon=1.529, min_samples=8\n",
      "Testing combination 3/20: epsilon=1.529, min_samples=9\n",
      "Testing combination 4/20: epsilon=1.529, min_samples=10\n",
      "Testing combination 5/20: epsilon=1.734, min_samples=7\n",
      "Testing combination 6/20: epsilon=1.734, min_samples=8\n",
      "Testing combination 7/20: epsilon=1.734, min_samples=9\n",
      "Testing combination 8/20: epsilon=1.734, min_samples=10\n",
      "Testing combination 9/20: epsilon=1.938, min_samples=7\n",
      "Testing combination 10/20: epsilon=1.938, min_samples=8\n",
      "Testing combination 11/20: epsilon=1.938, min_samples=9\n",
      "Testing combination 12/20: epsilon=1.938, min_samples=10\n",
      "Testing combination 13/20: epsilon=2.143, min_samples=7\n",
      "Testing combination 14/20: epsilon=2.143, min_samples=8\n",
      "Testing combination 15/20: epsilon=2.143, min_samples=9\n",
      "Testing combination 16/20: epsilon=2.143, min_samples=10\n",
      "Testing combination 17/20: epsilon=2.348, min_samples=7\n",
      "Testing combination 18/20: epsilon=2.348, min_samples=8\n",
      "Testing combination 19/20: epsilon=2.348, min_samples=9\n",
      "Testing combination 20/20: epsilon=2.348, min_samples=10\n",
      "\n",
      "Top 5 parameter combinations:\n",
      "  1. epsilon=2.348, min_samples=9, clusters=2, noise=0.310, silhouette=0.356, score=0.300\n",
      "  2. epsilon=1.529, min_samples=10, clusters=2, noise=0.616, silhouette=0.132, score=0.092\n",
      "  3. epsilon=1.529, min_samples=7, clusters=1, noise=0.542, silhouette=0.000, score=0.000\n",
      "  4. epsilon=1.529, min_samples=8, clusters=1, noise=0.547, silhouette=0.000, score=0.000\n",
      "  5. epsilon=1.529, min_samples=9, clusters=1, noise=0.591, silhouette=0.000, score=0.000\n",
      "   DBSCAN: clusters=2, noise_ratio=0.310, silhouette=0.356\n",
      "\n",
      "============================================================\n",
      "Processing: statlog (ID: 144)\n",
      "============================================================\n",
      "Loading dataset ID: 144\n",
      "\n",
      " Categorical features detected:\n",
      "   - Attribute1\n",
      "   - Attribute3\n",
      "   - Attribute4\n",
      "   - Attribute6\n",
      "   - Attribute7\n",
      "   - Attribute9\n",
      "   - Attribute10\n",
      "   - Attribute12\n",
      "   - Attribute14\n",
      "   - Attribute15\n",
      "   - Attribute17\n",
      "   - Attribute19\n",
      "   - Attribute20\n",
      "\n",
      " Keeping 7 numerical features for clustering:\n",
      "   - Attribute2\n",
      "   - Attribute5\n",
      "   - Attribute8\n",
      "   - Attribute11\n",
      "   - Attribute13\n",
      "   - Attribute16\n",
      "   - Attribute18\n",
      " Loaded Statlog (German Credit Data): 1000 samples, 7 features\n",
      "   Removed 13 categorical features\n",
      "Preprocessing data...\n",
      "Data preprocessing completed.\n",
      "Running K-means analysis for Statlog (German Credit Data)...\n",
      "Finding optimal number of clusters (k=1 to 10)...\n",
      "Testing k=1...\n",
      "Converged after 2 iterations\n",
      "Testing k=2...\n",
      "Converged after 13 iterations\n",
      "Testing k=3...\n",
      "Converged after 10 iterations\n",
      "Testing k=4...\n",
      "Converged after 24 iterations\n",
      "Testing k=5...\n",
      "Converged after 25 iterations\n",
      "Testing k=6...\n",
      "Converged after 17 iterations\n",
      "Testing k=7...\n",
      "Converged after 11 iterations\n",
      "Testing k=8...\n",
      "Converged after 10 iterations\n",
      "Testing k=9...\n",
      "Converged after 19 iterations\n",
      "Testing k=10...\n",
      "Converged after 21 iterations\n",
      "Converged after 17 iterations\n",
      "   K-means: k=6, silhouette=0.189\n",
      "Running DBSCAN analysis for Statlog (German Credit Data)...\n",
      "   Using 20 parameter combinations for 1000 samples\n",
      "  - Computing k-distance graph for epsilon range selection...\n",
      "  - epsilon range: 0.689 to 1.339\n",
      "  - min_samples range: 3 to 14\n",
      "Testing combination 1/20: epsilon=0.689, min_samples=3\n",
      "Testing combination 2/20: epsilon=0.689, min_samples=7\n",
      "Testing combination 3/20: epsilon=0.689, min_samples=11\n",
      "Testing combination 4/20: epsilon=0.782, min_samples=3\n",
      "Testing combination 5/20: epsilon=0.782, min_samples=7\n",
      "Testing combination 6/20: epsilon=0.782, min_samples=11\n",
      "Testing combination 7/20: epsilon=0.875, min_samples=3\n",
      "Testing combination 8/20: epsilon=0.875, min_samples=7\n",
      "Testing combination 9/20: epsilon=0.875, min_samples=11\n",
      "Testing combination 10/20: epsilon=0.968, min_samples=3\n",
      "Testing combination 11/20: epsilon=0.968, min_samples=7\n",
      "Testing combination 12/20: epsilon=0.968, min_samples=11\n",
      "Testing combination 13/20: epsilon=1.061, min_samples=3\n",
      "Testing combination 14/20: epsilon=1.061, min_samples=7\n",
      "Testing combination 15/20: epsilon=1.061, min_samples=11\n",
      "Testing combination 16/20: epsilon=1.154, min_samples=3\n",
      "Testing combination 17/20: epsilon=1.154, min_samples=7\n",
      "Testing combination 18/20: epsilon=1.154, min_samples=11\n",
      "Testing combination 19/20: epsilon=1.247, min_samples=3\n",
      "Testing combination 20/20: epsilon=1.247, min_samples=7\n",
      "\n",
      "Top 5 parameter combinations:\n",
      "  1. epsilon=0.689, min_samples=11, clusters=8, noise=0.796, silhouette=0.341, score=0.205\n",
      "  2. epsilon=0.689, min_samples=7, clusters=23, noise=0.600, silhouette=0.261, score=0.183\n",
      "  3. epsilon=1.154, min_samples=11, clusters=3, noise=0.305, silhouette=0.207, score=0.175\n",
      "  4. epsilon=1.061, min_samples=11, clusters=3, noise=0.352, silhouette=0.212, score=0.175\n",
      "  5. epsilon=1.061, min_samples=7, clusters=5, noise=0.275, silhouette=0.202, score=0.175\n",
      "   DBSCAN: clusters=8, noise_ratio=0.796, silhouette=0.341\n",
      "\n",
      "============================================================\n",
      "Processing: breast_cancer (ID: 15)\n",
      "============================================================\n",
      "Loading dataset ID: 15\n",
      " Loaded Breast Cancer Wisconsin (Original): 699 samples, 9 features\n",
      "Preprocessing data...\n",
      "Data preprocessing completed.\n",
      "Running K-means analysis for Breast Cancer Wisconsin (Original)...\n",
      "Finding optimal number of clusters (k=1 to 10)...\n",
      "Testing k=1...\n",
      "Converged after 2 iterations\n",
      "Testing k=2...\n",
      "Converged after 7 iterations\n",
      "Testing k=3...\n",
      "Converged after 5 iterations\n",
      "Testing k=4...\n",
      "Converged after 12 iterations\n",
      "Testing k=5...\n",
      "Converged after 10 iterations\n",
      "Testing k=6...\n",
      "Converged after 9 iterations\n",
      "Testing k=7...\n",
      "Converged after 12 iterations\n",
      "Testing k=8...\n",
      "Converged after 12 iterations\n",
      "Testing k=9...\n",
      "Converged after 14 iterations\n",
      "Testing k=10...\n",
      "Converged after 23 iterations\n",
      "Converged after 7 iterations\n",
      "   K-means: k=2, silhouette=0.573\n",
      "Running DBSCAN analysis for Breast Cancer Wisconsin (Original)...\n",
      "   Using 20 parameter combinations for 683 samples\n",
      "  - Computing k-distance graph for epsilon range selection...\n",
      "  - epsilon range: 0.000 to 1.873\n",
      "  - min_samples range: 4 to 18\n",
      "Testing combination 1/20: epsilon=0.000, min_samples=4\n",
      "Testing combination 2/20: epsilon=0.000, min_samples=10\n",
      "Testing combination 3/20: epsilon=0.000, min_samples=16\n",
      "Testing combination 4/20: epsilon=0.268, min_samples=7\n",
      "Testing combination 5/20: epsilon=0.268, min_samples=13\n",
      "Testing combination 6/20: epsilon=0.535, min_samples=4\n",
      "Testing combination 7/20: epsilon=0.535, min_samples=10\n",
      "Testing combination 8/20: epsilon=0.535, min_samples=16\n",
      "Testing combination 9/20: epsilon=0.803, min_samples=7\n",
      "Testing combination 10/20: epsilon=0.803, min_samples=13\n",
      "Testing combination 11/20: epsilon=1.070, min_samples=4\n",
      "Testing combination 12/20: epsilon=1.070, min_samples=10\n",
      "Testing combination 13/20: epsilon=1.070, min_samples=16\n",
      "Testing combination 14/20: epsilon=1.338, min_samples=7\n",
      "Testing combination 15/20: epsilon=1.338, min_samples=13\n",
      "Testing combination 16/20: epsilon=1.605, min_samples=4\n",
      "Testing combination 17/20: epsilon=1.605, min_samples=10\n",
      "Testing combination 18/20: epsilon=1.605, min_samples=16\n",
      "Testing combination 19/20: epsilon=1.873, min_samples=7\n",
      "Testing combination 20/20: epsilon=1.873, min_samples=13\n",
      "\n",
      "Top 5 parameter combinations:\n",
      "  1. epsilon=0.000, min_samples=4, clusters=20, noise=0.678, silhouette=1.000, score=0.661\n",
      "  2. epsilon=0.268, min_samples=7, clusters=16, noise=0.704, silhouette=1.000, score=0.648\n",
      "  3. epsilon=0.000, min_samples=10, clusters=10, noise=0.776, silhouette=1.000, score=0.612\n",
      "  4. epsilon=1.873, min_samples=13, clusters=2, noise=0.204, silhouette=0.645, score=0.580\n",
      "  5. epsilon=0.000, min_samples=16, clusters=4, noise=0.867, silhouette=1.000, score=0.567\n",
      "   DBSCAN: clusters=20, noise_ratio=0.678, silhouette=1.000\n",
      "\n",
      "================================================================================\n",
      "GENERATING COMPARISON VISUALIZATIONS\n",
      "================================================================================\n",
      "\n",
      "1. Creating elbow method comparison...\n",
      "Elbow method comparison saved to: comparison\\1_elbow_method_all_datasets.png\n",
      "\n",
      "2. Creating silhouette analysis comparisons...\n",
      "Converged after 6 iterations\n",
      "Converged after 6 iterations\n",
      "Converged after 14 iterations\n",
      "Converged after 7 iterations\n",
      "Converged after 8 iterations\n",
      "Converged after 8 iterations\n",
      "Converged after 5 iterations\n",
      "Converged after 11 iterations\n",
      "Converged after 11 iterations\n",
      "Silhouette analysis for Iris saved to: comparison\\2_silhouette_analysis_iris.png\n",
      "Converged after 7 iterations\n",
      "Converged after 5 iterations\n",
      "Converged after 5 iterations\n",
      "Converged after 8 iterations\n",
      "Converged after 18 iterations\n",
      "Converged after 7 iterations\n",
      "Converged after 5 iterations\n",
      "Converged after 5 iterations\n",
      "Converged after 6 iterations\n",
      "Silhouette analysis for Wine saved to: comparison\\2_silhouette_analysis_wine.png\n",
      "Converged after 2 iterations\n",
      "Converged after 6 iterations\n",
      "Converged after 10 iterations\n",
      "Converged after 8 iterations\n",
      "Converged after 8 iterations\n",
      "Converged after 8 iterations\n",
      "Converged after 6 iterations\n",
      "Converged after 12 iterations\n",
      "Converged after 12 iterations\n",
      "Silhouette analysis for Wholesale customers saved to: comparison\\2_silhouette_analysis_wholesale_customers.png\n",
      "Converged after 7 iterations\n",
      "Converged after 6 iterations\n",
      "Converged after 6 iterations\n",
      "Converged after 10 iterations\n",
      "Converged after 14 iterations\n",
      "Converged after 16 iterations\n",
      "Converged after 16 iterations\n",
      "Converged after 13 iterations\n",
      "Converged after 16 iterations\n",
      "Silhouette analysis for Heart Disease saved to: comparison\\2_silhouette_analysis_heart_disease.png\n",
      "Converged after 7 iterations\n",
      "Converged after 8 iterations\n",
      "Converged after 13 iterations\n",
      "Converged after 22 iterations\n",
      "Converged after 21 iterations\n",
      "Converged after 14 iterations\n",
      "Converged after 17 iterations\n",
      "Converged after 9 iterations\n",
      "Converged after 19 iterations\n",
      "Silhouette analysis for Heart Failure Clinical Records saved to: comparison\\2_silhouette_analysis_heart_failure_clinical_records.png\n",
      "Converged after 3 iterations\n",
      "Converged after 16 iterations\n",
      "Converged after 16 iterations\n",
      "Converged after 18 iterations\n",
      "Converged after 18 iterations\n",
      "Converged after 15 iterations\n",
      "Converged after 24 iterations\n",
      "Converged after 24 iterations\n",
      "Converged after 24 iterations\n",
      "Silhouette analysis for Energy Efficiency saved to: comparison\\2_silhouette_analysis_energy_efficiency.png\n",
      "Converged after 10 iterations\n",
      "Converged after 8 iterations\n",
      "Converged after 12 iterations\n",
      "Converged after 8 iterations\n",
      "Converged after 13 iterations\n",
      "Converged after 18 iterations\n",
      "Converged after 13 iterations\n",
      "Converged after 14 iterations\n",
      "Converged after 14 iterations\n",
      "Silhouette analysis for Credit Approval saved to: comparison\\2_silhouette_analysis_credit_approval.png\n",
      "Converged after 8 iterations\n",
      "Converged after 4 iterations\n",
      "Converged after 15 iterations\n",
      "Converged after 12 iterations\n",
      "Converged after 11 iterations\n",
      "Converged after 9 iterations\n",
      "Converged after 11 iterations\n",
      "Converged after 9 iterations\n",
      "Converged after 5 iterations\n",
      "Silhouette analysis for Chronic Kidney Disease saved to: comparison\\2_silhouette_analysis_chronic_kidney_disease.png\n",
      "Converged after 13 iterations\n",
      "Converged after 10 iterations\n",
      "Converged after 24 iterations\n",
      "Converged after 25 iterations\n",
      "Converged after 17 iterations\n",
      "Converged after 11 iterations\n",
      "Converged after 10 iterations\n",
      "Converged after 19 iterations\n",
      "Converged after 21 iterations\n",
      "Silhouette analysis for Statlog (German Credit Data) saved to: comparison\\2_silhouette_analysis_statlog_(german_credit_data).png\n",
      "Converged after 7 iterations\n",
      "Converged after 5 iterations\n",
      "Converged after 12 iterations\n",
      "Converged after 10 iterations\n",
      "Converged after 9 iterations\n",
      "Converged after 12 iterations\n",
      "Converged after 12 iterations\n",
      "Converged after 14 iterations\n",
      "Converged after 23 iterations\n",
      "Silhouette analysis for Breast Cancer Wisconsin (Original) saved to: comparison\\2_silhouette_analysis_breast_cancer_wisconsin_(original).png\n",
      "\n",
      "3. Creating cluster size comparisons...\n",
      "Cluster size comparison for Iris saved to: comparison\\3_cluster_sizes_iris.png\n",
      "Cluster size comparison for Wine saved to: comparison\\3_cluster_sizes_wine.png\n",
      "Cluster size comparison for Wholesale customers saved to: comparison\\3_cluster_sizes_wholesale_customers.png\n",
      "Cluster size comparison for Heart Disease saved to: comparison\\3_cluster_sizes_heart_disease.png\n",
      "Cluster size comparison for Heart Failure Clinical Records saved to: comparison\\3_cluster_sizes_heart_failure_clinical_records.png\n",
      "Cluster size comparison for Energy Efficiency saved to: comparison\\3_cluster_sizes_energy_efficiency.png\n",
      "Cluster size comparison for Credit Approval saved to: comparison\\3_cluster_sizes_credit_approval.png\n",
      "Cluster size comparison for Chronic Kidney Disease saved to: comparison\\3_cluster_sizes_chronic_kidney_disease.png\n",
      "Cluster size comparison for Statlog (German Credit Data) saved to: comparison\\3_cluster_sizes_statlog_(german_credit_data).png\n",
      "Cluster size comparison for Breast Cancer Wisconsin (Original) saved to: comparison\\3_cluster_sizes_breast_cancer_wisconsin_(original).png\n",
      "\n",
      "4. Creating silhouette score by parameters plots...\n",
      "Silhouette score by parameters for Iris saved to: comparison\\4_silhouette_by_params_iris.png\n",
      "Silhouette score by parameters for Wine saved to: comparison\\4_silhouette_by_params_wine.png\n",
      "Silhouette score by parameters for Wholesale customers saved to: comparison\\4_silhouette_by_params_wholesale_customers.png\n",
      "Silhouette score by parameters for Heart Disease saved to: comparison\\4_silhouette_by_params_heart_disease.png\n",
      "Silhouette score by parameters for Heart Failure Clinical Records saved to: comparison\\4_silhouette_by_params_heart_failure_clinical_records.png\n",
      "Silhouette score by parameters for Energy Efficiency saved to: comparison\\4_silhouette_by_params_energy_efficiency.png\n",
      "Silhouette score by parameters for Credit Approval saved to: comparison\\4_silhouette_by_params_credit_approval.png\n",
      "Silhouette score by parameters for Chronic Kidney Disease saved to: comparison\\4_silhouette_by_params_chronic_kidney_disease.png\n",
      "Silhouette score by parameters for Statlog (German Credit Data) saved to: comparison\\4_silhouette_by_params_statlog_(german_credit_data).png\n",
      "Silhouette score by parameters for Breast Cancer Wisconsin (Original) saved to: comparison\\4_silhouette_by_params_breast_cancer_wisconsin_(original).png\n",
      "\n",
      "5. Creating noise ratio by parameters plots...\n",
      "Noise ratio by parameters for Iris saved to: comparison\\5_noise_ratio_by_params_iris.png\n",
      "Noise ratio by parameters for Wine saved to: comparison\\5_noise_ratio_by_params_wine.png\n",
      "Noise ratio by parameters for Wholesale customers saved to: comparison\\5_noise_ratio_by_params_wholesale_customers.png\n",
      "Noise ratio by parameters for Heart Disease saved to: comparison\\5_noise_ratio_by_params_heart_disease.png\n",
      "Noise ratio by parameters for Heart Failure Clinical Records saved to: comparison\\5_noise_ratio_by_params_heart_failure_clinical_records.png\n",
      "Noise ratio by parameters for Energy Efficiency saved to: comparison\\5_noise_ratio_by_params_energy_efficiency.png\n",
      "Noise ratio by parameters for Credit Approval saved to: comparison\\5_noise_ratio_by_params_credit_approval.png\n",
      "Noise ratio by parameters for Chronic Kidney Disease saved to: comparison\\5_noise_ratio_by_params_chronic_kidney_disease.png\n",
      "Noise ratio by parameters for Statlog (German Credit Data) saved to: comparison\\5_noise_ratio_by_params_statlog_(german_credit_data).png\n",
      "Noise ratio by parameters for Breast Cancer Wisconsin (Original) saved to: comparison\\5_noise_ratio_by_params_breast_cancer_wisconsin_(original).png\n",
      "\n",
      "6. Creating clustering visualizations...\n",
      "Clustering visualization for Iris saved to: comparison\\6_clustering_visualization_iris.png\n",
      "Clustering visualization for Wine saved to: comparison\\6_clustering_visualization_wine.png\n",
      "Clustering visualization for Wholesale customers saved to: comparison\\6_clustering_visualization_wholesale_customers.png\n",
      "Clustering visualization for Heart Disease saved to: comparison\\6_clustering_visualization_heart_disease.png\n",
      "Clustering visualization for Heart Failure Clinical Records saved to: comparison\\6_clustering_visualization_heart_failure_clinical_records.png\n",
      "Clustering visualization for Energy Efficiency saved to: comparison\\6_clustering_visualization_energy_efficiency.png\n",
      "Clustering visualization for Credit Approval saved to: comparison\\6_clustering_visualization_credit_approval.png\n",
      "Clustering visualization for Chronic Kidney Disease saved to: comparison\\6_clustering_visualization_chronic_kidney_disease.png\n",
      "Clustering visualization for Statlog (German Credit Data) saved to: comparison\\6_clustering_visualization_statlog_german_credit_data.png\n",
      "Clustering visualization for Breast Cancer Wisconsin (Original) saved to: comparison\\6_clustering_visualization_breast_cancer_wisconsin_original.png\n",
      "\n",
      "7. Creating comprehensive text report...\n",
      "Comparison report saved to: comparison\\comparison.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef85684b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
